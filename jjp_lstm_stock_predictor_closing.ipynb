{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Closing Prices\n",
    "\n",
    "In this notebook, you will build and train a custom LSTM RNN that uses a 10 day window of Bitcoin closing prices to predict the 11th day closing price. \n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Prepare the data for training and testing\n",
    "2. Build and train a custom LSTM RNN\n",
    "3. Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, you will need to prepare the training and testing data for the model. The model will use a rolling 10 day window to predict the 11th day closing price.\n",
    "\n",
    "You will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the X and y values\n",
    "4. Reshape the X_train and X_test data for the model. Note: The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMM</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AES</th>\n",
       "      <th>...</th>\n",
       "      <th>WLTW</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-01 00:00:00+00:00</th>\n",
       "      <td>207.49</td>\n",
       "      <td>78.59</td>\n",
       "      <td>80.10</td>\n",
       "      <td>348.06</td>\n",
       "      <td>164.20</td>\n",
       "      <td>42.84</td>\n",
       "      <td>264.01</td>\n",
       "      <td>23.68</td>\n",
       "      <td>160.62</td>\n",
       "      <td>17.50</td>\n",
       "      <td>...</td>\n",
       "      <td>172.56</td>\n",
       "      <td>125.12</td>\n",
       "      <td>54.92</td>\n",
       "      <td>31.29</td>\n",
       "      <td>126.64</td>\n",
       "      <td>76.37</td>\n",
       "      <td>95.37</td>\n",
       "      <td>125.41</td>\n",
       "      <td>51.17</td>\n",
       "      <td>95.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-04 00:00:00+00:00</th>\n",
       "      <td>206.86</td>\n",
       "      <td>78.62</td>\n",
       "      <td>79.46</td>\n",
       "      <td>338.20</td>\n",
       "      <td>162.82</td>\n",
       "      <td>41.79</td>\n",
       "      <td>258.16</td>\n",
       "      <td>23.37</td>\n",
       "      <td>158.40</td>\n",
       "      <td>17.12</td>\n",
       "      <td>...</td>\n",
       "      <td>173.05</td>\n",
       "      <td>125.57</td>\n",
       "      <td>55.08</td>\n",
       "      <td>31.36</td>\n",
       "      <td>122.81</td>\n",
       "      <td>76.25</td>\n",
       "      <td>95.14</td>\n",
       "      <td>124.43</td>\n",
       "      <td>50.86</td>\n",
       "      <td>95.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-05 00:00:00+00:00</th>\n",
       "      <td>203.84</td>\n",
       "      <td>78.22</td>\n",
       "      <td>78.91</td>\n",
       "      <td>333.21</td>\n",
       "      <td>163.67</td>\n",
       "      <td>41.88</td>\n",
       "      <td>257.38</td>\n",
       "      <td>23.50</td>\n",
       "      <td>157.31</td>\n",
       "      <td>17.42</td>\n",
       "      <td>...</td>\n",
       "      <td>182.04</td>\n",
       "      <td>124.14</td>\n",
       "      <td>54.90</td>\n",
       "      <td>31.09</td>\n",
       "      <td>122.95</td>\n",
       "      <td>76.19</td>\n",
       "      <td>95.93</td>\n",
       "      <td>124.11</td>\n",
       "      <td>50.79</td>\n",
       "      <td>95.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-06 00:00:00+00:00</th>\n",
       "      <td>202.80</td>\n",
       "      <td>77.70</td>\n",
       "      <td>78.09</td>\n",
       "      <td>317.85</td>\n",
       "      <td>162.39</td>\n",
       "      <td>42.56</td>\n",
       "      <td>256.40</td>\n",
       "      <td>22.41</td>\n",
       "      <td>157.97</td>\n",
       "      <td>17.58</td>\n",
       "      <td>...</td>\n",
       "      <td>170.88</td>\n",
       "      <td>123.55</td>\n",
       "      <td>55.09</td>\n",
       "      <td>30.85</td>\n",
       "      <td>121.36</td>\n",
       "      <td>75.85</td>\n",
       "      <td>96.60</td>\n",
       "      <td>123.24</td>\n",
       "      <td>49.67</td>\n",
       "      <td>94.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-07 00:00:00+00:00</th>\n",
       "      <td>199.86</td>\n",
       "      <td>76.80</td>\n",
       "      <td>78.24</td>\n",
       "      <td>317.42</td>\n",
       "      <td>161.85</td>\n",
       "      <td>41.42</td>\n",
       "      <td>255.46</td>\n",
       "      <td>22.08</td>\n",
       "      <td>154.13</td>\n",
       "      <td>17.67</td>\n",
       "      <td>...</td>\n",
       "      <td>170.20</td>\n",
       "      <td>118.67</td>\n",
       "      <td>55.52</td>\n",
       "      <td>30.24</td>\n",
       "      <td>119.91</td>\n",
       "      <td>75.32</td>\n",
       "      <td>96.54</td>\n",
       "      <td>121.39</td>\n",
       "      <td>48.71</td>\n",
       "      <td>92.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              MMM    ABT   ABBV    ABMD     ACN   ATVI  \\\n",
       "date                                                                     \n",
       "2019-03-01 00:00:00+00:00  207.49  78.59  80.10  348.06  164.20  42.84   \n",
       "2019-03-04 00:00:00+00:00  206.86  78.62  79.46  338.20  162.82  41.79   \n",
       "2019-03-05 00:00:00+00:00  203.84  78.22  78.91  333.21  163.67  41.88   \n",
       "2019-03-06 00:00:00+00:00  202.80  77.70  78.09  317.85  162.39  42.56   \n",
       "2019-03-07 00:00:00+00:00  199.86  76.80  78.24  317.42  161.85  41.42   \n",
       "\n",
       "                             ADBE    AMD     AAP    AES  ...    WLTW    WYNN  \\\n",
       "date                                                     ...                   \n",
       "2019-03-01 00:00:00+00:00  264.01  23.68  160.62  17.50  ...  172.56  125.12   \n",
       "2019-03-04 00:00:00+00:00  258.16  23.37  158.40  17.12  ...  173.05  125.57   \n",
       "2019-03-05 00:00:00+00:00  257.38  23.50  157.31  17.42  ...  182.04  124.14   \n",
       "2019-03-06 00:00:00+00:00  256.40  22.41  157.97  17.58  ...  170.88  123.55   \n",
       "2019-03-07 00:00:00+00:00  255.46  22.08  154.13  17.67  ...  170.20  118.67   \n",
       "\n",
       "                             XEL    XRX    XLNX    XYL    YUM     ZBH   ZION  \\\n",
       "date                                                                           \n",
       "2019-03-01 00:00:00+00:00  54.92  31.29  126.64  76.37  95.37  125.41  51.17   \n",
       "2019-03-04 00:00:00+00:00  55.08  31.36  122.81  76.25  95.14  124.43  50.86   \n",
       "2019-03-05 00:00:00+00:00  54.90  31.09  122.95  76.19  95.93  124.11  50.79   \n",
       "2019-03-06 00:00:00+00:00  55.09  30.85  121.36  75.85  96.60  123.24  49.67   \n",
       "2019-03-07 00:00:00+00:00  55.52  30.24  119.91  75.32  96.54  121.39  48.71   \n",
       "\n",
       "                             ZTS  \n",
       "date                              \n",
       "2019-03-01 00:00:00+00:00  95.75  \n",
       "2019-03-04 00:00:00+00:00  95.87  \n",
       "2019-03-05 00:00:00+00:00  95.78  \n",
       "2019-03-06 00:00:00+00:00  94.17  \n",
       "2019-03-07 00:00:00+00:00  92.55  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the stock prices\n",
    "df = pd.read_csv('sp500_close.csv', index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "#df = df[\"chosen stocks\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous closing prices\n",
    "# Try a window size anywhere from 1 to 10 and see how the model performance changes\n",
    "#jjp - need to add a for loop \n",
    "\n",
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 5\n",
    "\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 0\n",
    "target_column = 0\n",
    "X, y = window_data(df, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remaineder for testing\n",
    "# YOUR CODE HERE!\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split = int(0.7 *len(X))\n",
    "X_train_rnn = X[: split -1]\n",
    "X_test = X[split:]\n",
    "y_train_rnn = y[: split -1]\n",
    "y_test = y[split:]\n",
    "\n",
    "X_train_rnn, X_val_rnn, y_train_rnn, y_val_rnn = train_test_split(X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MinMaxScaler to scale the data between 0 and 1. \n",
    "# YOUR CODE HERE!\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train_rnn =scaler.transform(X_train_rnn)\n",
    "X_val_rnn =scaler.transform(X_val_rnn)\n",
    "X_test = scaler.transform(X_test)\n",
    "scaler.fit(y)\n",
    "y_train_rnn = scaler.transform(y_train_rnn)\n",
    "y_val_rnn = scaler.transform(y_val_rnn)\n",
    "y_test =scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[0.59525887]\n",
      "  [0.5740256 ]\n",
      "  [0.56384526]\n",
      "  [0.53984859]\n",
      "  [0.52167928]]\n",
      "\n",
      " [[0.2408377 ]\n",
      "  [0.27632344]\n",
      "  [0.22004072]\n",
      "  [0.26483138]\n",
      "  [0.22711631]]\n",
      "\n",
      " [[0.50145433]\n",
      "  [0.46974985]\n",
      "  [0.41273997]\n",
      "  [0.43688919]\n",
      "  [0.39132829]]\n",
      "\n",
      " [[0.2443281 ]\n",
      "  [0.26207097]\n",
      "  [0.16215823]\n",
      "  [0.26483138]\n",
      "  [0.30571232]]\n",
      "\n",
      " [[0.97294939]\n",
      "  [0.99098313]\n",
      "  [0.98603839]\n",
      "  [1.        ]\n",
      "  [0.99421886]]] \n",
      "\n",
      "X_val_rnn sample values:\n",
      "[[[0.32867946]\n",
      "  [0.3214078 ]\n",
      "  [0.37449098]\n",
      "  [0.38293187]\n",
      "  [0.36077082]]\n",
      "\n",
      " [[0.16521233]\n",
      "  [0.20564282]\n",
      "  [0.11736475]\n",
      "  [0.1375086 ]\n",
      "  [0.20165175]]\n",
      "\n",
      " [[0.84045957]\n",
      "  [0.82955207]\n",
      "  [0.89005236]\n",
      "  [0.89855471]\n",
      "  [0.91231934]]\n",
      "\n",
      " [[0.2552356 ]\n",
      "  [0.26425247]\n",
      "  [0.26570681]\n",
      "  [0.30282175]\n",
      "  [0.27309016]]\n",
      "\n",
      " [[0.30642816]\n",
      "  [0.26687027]\n",
      "  [0.22556719]\n",
      "  [0.28148658]\n",
      "  [0.31507226]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[0.35136707]\n",
      "  [0.35674811]\n",
      "  [0.33827807]\n",
      "  [0.38086717]\n",
      "  [0.36200964]]\n",
      "\n",
      " [[0.35674811]\n",
      "  [0.33827807]\n",
      "  [0.34584061]\n",
      "  [0.36200964]\n",
      "  [0.32016518]]\n",
      "\n",
      " [[0.33827807]\n",
      "  [0.34584061]\n",
      "  [0.32591623]\n",
      "  [0.32016518]\n",
      "  [0.33021335]]\n",
      "\n",
      " [[0.34584061]\n",
      "  [0.32591623]\n",
      "  [0.28170448]\n",
      "  [0.33021335]\n",
      "  [0.32622161]]\n",
      "\n",
      " [[0.32591623]\n",
      "  [0.28170448]\n",
      "  [0.29232112]\n",
      "  [0.32622161]\n",
      "  [0.33145217]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "# YOUR CODE HERE!\n",
    "X_train_rnn = X_train_rnn.reshape((X_train_rnn.shape[0], X_train_rnn.shape[1], 1))\n",
    "X_val_rnn = X_val_rnn.reshape((X_val_rnn.shape[0], X_val_rnn.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print (f\"X_train sample values:\\n{X_train_rnn[:5]} \\n\")\n",
    "print (f\"X_val_rnn sample values:\\n{X_val_rnn[:5]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, you will design a custom LSTM RNN and fit (train) it using the training data.\n",
    "\n",
    "You will need to:\n",
    "1. Define the model architecture\n",
    "2. Compile the model\n",
    "3. Fit the model to the training data\n",
    "\n",
    "### Hints:\n",
    "You will want to use the same model architecture and random seed for both notebooks. This is necessary to accurately compare the performance of the FNG model vs the closing price model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model. \n",
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# YOUR CODE HERE!\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 30\n",
    "dropout_fraction = 0.5\n",
    "\n",
    "#first layer:\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train_rnn.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#second layer\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#third layer\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#fourth layer\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "#output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# YOUR CODE HERE!\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 5, 30)             3840      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 30)             7320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5, 30)             7320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 25,831\n",
      "Trainable params: 25,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "# YOUR CODE HERE!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples, validate on 43 samples\n",
      "Epoch 1/250\n",
      "128/128 [==============================] - 6s 44ms/sample - loss: 0.2263 - val_loss: 0.2054\n",
      "Epoch 2/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.1997 - val_loss: 0.1795\n",
      "Epoch 3/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.1747 - val_loss: 0.1509\n",
      "Epoch 4/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.1477 - val_loss: 0.1195\n",
      "Epoch 5/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.1099 - val_loss: 0.0867\n",
      "Epoch 6/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0846 - val_loss: 0.0571\n",
      "Epoch 7/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0656 - val_loss: 0.0389\n",
      "Epoch 8/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0431 - val_loss: 0.0376\n",
      "Epoch 9/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0590 - val_loss: 0.0416\n",
      "Epoch 10/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0679 - val_loss: 0.0371\n",
      "Epoch 11/250\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.0523 - val_loss: 0.0305\n",
      "Epoch 12/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0412 - val_loss: 0.0285\n",
      "Epoch 13/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0413 - val_loss: 0.0270\n",
      "Epoch 14/250\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.0404 - val_loss: 0.0243\n",
      "Epoch 15/250\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 0.0309 - val_loss: 0.0207\n",
      "Epoch 16/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0308 - val_loss: 0.0172\n",
      "Epoch 17/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0331 - val_loss: 0.0136\n",
      "Epoch 18/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0257 - val_loss: 0.0110\n",
      "Epoch 19/250\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.0302 - val_loss: 0.0092\n",
      "Epoch 20/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0243 - val_loss: 0.0079\n",
      "Epoch 21/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0289 - val_loss: 0.0075\n",
      "Epoch 22/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0314 - val_loss: 0.0073\n",
      "Epoch 23/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0239 - val_loss: 0.0077\n",
      "Epoch 24/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0137 - val_loss: 0.0085\n",
      "Epoch 25/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0196 - val_loss: 0.0078\n",
      "Epoch 26/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0178 - val_loss: 0.0073\n",
      "Epoch 27/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0195 - val_loss: 0.0072\n",
      "Epoch 28/250\n",
      "128/128 [==============================] - 0s 460us/sample - loss: 0.0325 - val_loss: 0.0081\n",
      "Epoch 29/250\n",
      "128/128 [==============================] - 0s 421us/sample - loss: 0.0174 - val_loss: 0.0082\n",
      "Epoch 30/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0186 - val_loss: 0.0081\n",
      "Epoch 31/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0183 - val_loss: 0.0079\n",
      "Epoch 32/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0153 - val_loss: 0.0074\n",
      "Epoch 33/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0220 - val_loss: 0.0073\n",
      "Epoch 34/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0260 - val_loss: 0.0078\n",
      "Epoch 35/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0214 - val_loss: 0.0091\n",
      "Epoch 36/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0211 - val_loss: 0.0089\n",
      "Epoch 37/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0297 - val_loss: 0.0079\n",
      "Epoch 38/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0228 - val_loss: 0.0076\n",
      "Epoch 39/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0190 - val_loss: 0.0095\n",
      "Epoch 40/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0272 - val_loss: 0.0102\n",
      "Epoch 41/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0232 - val_loss: 0.0091\n",
      "Epoch 42/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0169 - val_loss: 0.0080\n",
      "Epoch 43/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0156 - val_loss: 0.0076\n",
      "Epoch 44/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0251 - val_loss: 0.0079\n",
      "Epoch 45/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0160 - val_loss: 0.0103\n",
      "Epoch 46/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0169 - val_loss: 0.0105\n",
      "Epoch 47/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0199 - val_loss: 0.0097\n",
      "Epoch 48/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0178 - val_loss: 0.0076\n",
      "Epoch 49/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0157 - val_loss: 0.0073\n",
      "Epoch 50/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0214 - val_loss: 0.0072\n",
      "Epoch 51/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0176 - val_loss: 0.0074\n",
      "Epoch 52/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0149 - val_loss: 0.0079\n",
      "Epoch 53/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0234 - val_loss: 0.0081\n",
      "Epoch 54/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0139 - val_loss: 0.0072\n",
      "Epoch 55/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0158 - val_loss: 0.0078\n",
      "Epoch 56/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0222 - val_loss: 0.0080\n",
      "Epoch 57/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0217 - val_loss: 0.0071\n",
      "Epoch 58/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0188 - val_loss: 0.0094\n",
      "Epoch 59/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0193 - val_loss: 0.0106\n",
      "Epoch 60/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0163 - val_loss: 0.0113\n",
      "Epoch 61/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0216 - val_loss: 0.0123\n",
      "Epoch 62/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0245 - val_loss: 0.0106\n",
      "Epoch 63/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0180 - val_loss: 0.0083\n",
      "Epoch 64/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0194 - val_loss: 0.0079\n",
      "Epoch 65/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0235 - val_loss: 0.0078\n",
      "Epoch 66/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0183 - val_loss: 0.0084\n",
      "Epoch 67/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 68/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0204 - val_loss: 0.0108\n",
      "Epoch 69/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0166 - val_loss: 0.0082\n",
      "Epoch 70/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0189 - val_loss: 0.0074\n",
      "Epoch 71/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0165 - val_loss: 0.0074\n",
      "Epoch 72/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0144 - val_loss: 0.0073\n",
      "Epoch 73/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0144 - val_loss: 0.0072\n",
      "Epoch 74/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0136 - val_loss: 0.0071\n",
      "Epoch 75/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 76/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0166 - val_loss: 0.0073\n",
      "Epoch 77/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0151 - val_loss: 0.0073\n",
      "Epoch 78/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0160 - val_loss: 0.0070\n",
      "Epoch 79/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0181 - val_loss: 0.0070\n",
      "Epoch 80/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0149 - val_loss: 0.0075\n",
      "Epoch 81/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0160 - val_loss: 0.0082\n",
      "Epoch 82/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0155 - val_loss: 0.0087\n",
      "Epoch 83/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0196 - val_loss: 0.0082\n",
      "Epoch 84/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0134 - val_loss: 0.0077\n",
      "Epoch 85/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0174 - val_loss: 0.0074\n",
      "Epoch 86/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0174 - val_loss: 0.0074\n",
      "Epoch 87/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0199 - val_loss: 0.0074\n",
      "Epoch 88/250\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.0169 - val_loss: 0.0098\n",
      "Epoch 89/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0222 - val_loss: 0.0094\n",
      "Epoch 90/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0141 - val_loss: 0.0072\n",
      "Epoch 91/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0140 - val_loss: 0.0076\n",
      "Epoch 92/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0218 - val_loss: 0.0074\n",
      "Epoch 93/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0169 - val_loss: 0.0069\n",
      "Epoch 94/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0216 - val_loss: 0.0084\n",
      "Epoch 95/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 96/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0190 - val_loss: 0.0095\n",
      "Epoch 97/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0209 - val_loss: 0.0076\n",
      "Epoch 98/250\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.0167 - val_loss: 0.0074\n",
      "Epoch 99/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0202 - val_loss: 0.0075\n",
      "Epoch 100/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0148 - val_loss: 0.0081\n",
      "Epoch 101/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 102/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0147 - val_loss: 0.0079\n",
      "Epoch 103/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0175 - val_loss: 0.0074\n",
      "Epoch 104/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0168 - val_loss: 0.0075\n",
      "Epoch 105/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0158 - val_loss: 0.0077\n",
      "Epoch 106/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0142 - val_loss: 0.0077\n",
      "Epoch 107/250\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.0173 - val_loss: 0.0088\n",
      "Epoch 108/250\n",
      "128/128 [==============================] - 0s 421us/sample - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 109/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0190 - val_loss: 0.0106\n",
      "Epoch 110/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0130 - val_loss: 0.0081\n",
      "Epoch 111/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0177 - val_loss: 0.0074\n",
      "Epoch 112/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0172 - val_loss: 0.0078\n",
      "Epoch 113/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0244 - val_loss: 0.0071\n",
      "Epoch 114/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0140 - val_loss: 0.0079\n",
      "Epoch 115/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0145 - val_loss: 0.0092\n",
      "Epoch 116/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0200 - val_loss: 0.0083\n",
      "Epoch 117/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0126 - val_loss: 0.0069\n",
      "Epoch 118/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0129 - val_loss: 0.0074\n",
      "Epoch 119/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0188 - val_loss: 0.0072\n",
      "Epoch 120/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0143 - val_loss: 0.0071\n",
      "Epoch 121/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0127 - val_loss: 0.0102\n",
      "Epoch 122/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0208 - val_loss: 0.0125\n",
      "Epoch 123/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0211 - val_loss: 0.0109\n",
      "Epoch 124/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0149 - val_loss: 0.0087\n",
      "Epoch 125/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0152 - val_loss: 0.0078\n",
      "Epoch 126/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0201 - val_loss: 0.0077\n",
      "Epoch 127/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0138 - val_loss: 0.0074\n",
      "Epoch 128/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0166 - val_loss: 0.0072\n",
      "Epoch 129/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0174 - val_loss: 0.0071\n",
      "Epoch 130/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0138 - val_loss: 0.0074\n",
      "Epoch 131/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0105 - val_loss: 0.0076\n",
      "Epoch 132/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0173 - val_loss: 0.0072\n",
      "Epoch 133/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0179 - val_loss: 0.0069\n",
      "Epoch 134/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0193 - val_loss: 0.0071\n",
      "Epoch 135/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0132 - val_loss: 0.0069\n",
      "Epoch 136/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0187 - val_loss: 0.0069\n",
      "Epoch 137/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0148 - val_loss: 0.0072\n",
      "Epoch 138/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0211 - val_loss: 0.0074\n",
      "Epoch 139/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0147 - val_loss: 0.0071\n",
      "Epoch 140/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0170 - val_loss: 0.0072\n",
      "Epoch 141/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0142 - val_loss: 0.0078\n",
      "Epoch 142/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0118 - val_loss: 0.0077\n",
      "Epoch 143/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0145 - val_loss: 0.0073\n",
      "Epoch 144/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0185 - val_loss: 0.0073\n",
      "Epoch 145/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0145 - val_loss: 0.0071\n",
      "Epoch 146/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0124 - val_loss: 0.0070\n",
      "Epoch 147/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0143 - val_loss: 0.0070\n",
      "Epoch 148/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0179 - val_loss: 0.0069\n",
      "Epoch 149/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 150/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0125 - val_loss: 0.0071\n",
      "Epoch 151/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0138 - val_loss: 0.0069\n",
      "Epoch 152/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0147 - val_loss: 0.0069\n",
      "Epoch 153/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0107 - val_loss: 0.0074\n",
      "Epoch 154/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0181 - val_loss: 0.0072\n",
      "Epoch 155/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0155 - val_loss: 0.0071\n",
      "Epoch 156/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0145 - val_loss: 0.0079\n",
      "Epoch 157/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0135 - val_loss: 0.0083\n",
      "Epoch 158/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0163 - val_loss: 0.0077\n",
      "Epoch 159/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0109 - val_loss: 0.0073\n",
      "Epoch 160/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0129 - val_loss: 0.0073\n",
      "Epoch 161/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0165 - val_loss: 0.0071\n",
      "Epoch 162/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0128 - val_loss: 0.0069\n",
      "Epoch 163/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0133 - val_loss: 0.0070\n",
      "Epoch 164/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0152 - val_loss: 0.0070\n",
      "Epoch 165/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0117 - val_loss: 0.0068\n",
      "Epoch 166/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0195 - val_loss: 0.0068\n",
      "Epoch 167/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0179 - val_loss: 0.0070\n",
      "Epoch 168/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0152 - val_loss: 0.0069\n",
      "Epoch 169/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0141 - val_loss: 0.0070\n",
      "Epoch 170/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 171/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0128 - val_loss: 0.0071\n",
      "Epoch 172/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0117 - val_loss: 0.0070\n",
      "Epoch 173/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0115 - val_loss: 0.0073\n",
      "Epoch 174/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0128 - val_loss: 0.0074\n",
      "Epoch 175/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0141 - val_loss: 0.0072\n",
      "Epoch 176/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0176 - val_loss: 0.0072\n",
      "Epoch 177/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0130 - val_loss: 0.0073\n",
      "Epoch 178/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0127 - val_loss: 0.0072\n",
      "Epoch 179/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0125 - val_loss: 0.0078\n",
      "Epoch 180/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0162 - val_loss: 0.0094\n",
      "Epoch 181/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0142 - val_loss: 0.0093\n",
      "Epoch 182/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0147 - val_loss: 0.0079\n",
      "Epoch 183/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0126 - val_loss: 0.0080\n",
      "Epoch 184/250\n",
      "128/128 [==============================] - 0s 421us/sample - loss: 0.0150 - val_loss: 0.0079\n",
      "Epoch 185/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0141 - val_loss: 0.0071\n",
      "Epoch 186/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0122 - val_loss: 0.0072\n",
      "Epoch 187/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0121 - val_loss: 0.0080\n",
      "Epoch 188/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0136 - val_loss: 0.0087\n",
      "Epoch 189/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0124 - val_loss: 0.0084\n",
      "Epoch 190/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0134 - val_loss: 0.0076\n",
      "Epoch 191/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0173 - val_loss: 0.0073\n",
      "Epoch 192/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0182 - val_loss: 0.0073\n",
      "Epoch 193/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0120 - val_loss: 0.0072\n",
      "Epoch 194/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0119 - val_loss: 0.0075\n",
      "Epoch 195/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0154 - val_loss: 0.0084\n",
      "Epoch 196/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 197/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0141 - val_loss: 0.0087\n",
      "Epoch 198/250\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.0144 - val_loss: 0.0079\n",
      "Epoch 199/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0121 - val_loss: 0.0072\n",
      "Epoch 200/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0098 - val_loss: 0.0074\n",
      "Epoch 201/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0120 - val_loss: 0.0071\n",
      "Epoch 202/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0100 - val_loss: 0.0068\n",
      "Epoch 203/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0132 - val_loss: 0.0070\n",
      "Epoch 204/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0134 - val_loss: 0.0068\n",
      "Epoch 205/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0170 - val_loss: 0.0068\n",
      "Epoch 206/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0141 - val_loss: 0.0068\n",
      "Epoch 207/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0175 - val_loss: 0.0077\n",
      "Epoch 208/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 209/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0193 - val_loss: 0.0110\n",
      "Epoch 210/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 211/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0149 - val_loss: 0.0088\n",
      "Epoch 212/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0167 - val_loss: 0.0083\n",
      "Epoch 213/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0161 - val_loss: 0.0081\n",
      "Epoch 214/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0122 - val_loss: 0.0075\n",
      "Epoch 215/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0126 - val_loss: 0.0074\n",
      "Epoch 216/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0118 - val_loss: 0.0080\n",
      "Epoch 217/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 218/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0165 - val_loss: 0.0072\n",
      "Epoch 219/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0143 - val_loss: 0.0068\n",
      "Epoch 220/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0142 - val_loss: 0.0070\n",
      "Epoch 221/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0140 - val_loss: 0.0070\n",
      "Epoch 222/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0127 - val_loss: 0.0068\n",
      "Epoch 223/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0155 - val_loss: 0.0068\n",
      "Epoch 224/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0132 - val_loss: 0.0067\n",
      "Epoch 225/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0180 - val_loss: 0.0067\n",
      "Epoch 226/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0145 - val_loss: 0.0067\n",
      "Epoch 227/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0148 - val_loss: 0.0070\n",
      "Epoch 228/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 229/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0136 - val_loss: 0.0072\n",
      "Epoch 230/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0144 - val_loss: 0.0072\n",
      "Epoch 231/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0172 - val_loss: 0.0074\n",
      "Epoch 232/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 233/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0153 - val_loss: 0.0083\n",
      "Epoch 234/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0144 - val_loss: 0.0083\n",
      "Epoch 235/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0131 - val_loss: 0.0084\n",
      "Epoch 236/250\n",
      "128/128 [==============================] - 0s 421us/sample - loss: 0.0147 - val_loss: 0.0079\n",
      "Epoch 237/250\n",
      "128/128 [==============================] - 0s 421us/sample - loss: 0.0127 - val_loss: 0.0072\n",
      "Epoch 238/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0120 - val_loss: 0.0070\n",
      "Epoch 239/250\n",
      "128/128 [==============================] - 0s 483us/sample - loss: 0.0132 - val_loss: 0.0070\n",
      "Epoch 240/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0094 - val_loss: 0.0068\n",
      "Epoch 241/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0139 - val_loss: 0.0067\n",
      "Epoch 242/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0149 - val_loss: 0.0071\n",
      "Epoch 243/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0126 - val_loss: 0.0072\n",
      "Epoch 244/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0107 - val_loss: 0.0069\n",
      "Epoch 245/250\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.0128 - val_loss: 0.0067\n",
      "Epoch 246/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 247/250\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 248/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0143 - val_loss: 0.0068\n",
      "Epoch 249/250\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.0129 - val_loss: 0.0077\n",
      "Epoch 250/250\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 0.0149 - val_loss: 0.0078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29e1ba92048>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "# YOUR CODE HERE!\n",
    "batch_size = 60\n",
    "epochs = 250\n",
    "model.fit(\n",
    "    X_train_rnn,\n",
    "    y_train_rnn,\n",
    "    validation_data=(X_val_rnn, y_val_rnn),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "In this section, you will evaluate the model using the test data. \n",
    "\n",
    "You will need to:\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the X_test data to make predictions\n",
    "3. Create a DataFrame of Real (y_test) vs predicted values. \n",
    "4. Plot the Real vs predicted values as a line chart\n",
    "\n",
    "### Hints\n",
    "Remember to apply the `inverse_transform` function to the predicted and y_test values to recover the actual closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 216us/sample - loss: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.005030172449108717"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# YOUR CODE HERE!\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "# YOUR CODE HERE!\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170.11</td>\n",
       "      <td>171.660049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170.84</td>\n",
       "      <td>171.411575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170.55</td>\n",
       "      <td>170.714478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170.93</td>\n",
       "      <td>170.182343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171.88</td>\n",
       "      <td>169.084229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Real   Predicted\n",
       "0  170.11  171.660049\n",
       "1  170.84  171.411575\n",
       "2  170.55  170.714478\n",
       "3  170.93  170.182343\n",
       "4  171.88  169.084229"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stock_closing = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "})\n",
    "stock_closing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29e2a3f52c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "# YOUR CODE HERE!\n",
    "stock_closing.plot(title='Close price predictions using LSTM RNN on closing price')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
